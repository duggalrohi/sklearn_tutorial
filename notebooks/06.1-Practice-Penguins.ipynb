{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "472ffaed",
   "metadata": {},
   "source": [
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/duggalrohi/sklearn_tutorial/blob/master/notebooks/06.1-Practice-Penguins.ipynb\">\n",
    "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
    "</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c9a0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77fcb6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%cd '/content/drive/MyDrive/'\n",
    "\n",
    "#!git clone https://github.com/duggalrohi/sklearn_tutorial.git\n",
    "%cd '/content/drive/MyDrive/sklearn_tutorial/notebooks/'\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b72207a-86d1-493f-8ccc-5eb5f90cf2b1",
   "metadata": {},
   "source": [
    "# Practice Session: Palmer Penguins dataset\n",
    "\n",
    "In the section, we will practice the steps learned so far on a new dataset: the\n",
    "Palmer Penguins dataset.\n",
    "\n",
    "<img alt=\"penguins\" src=\"https://raw.githubusercontent.com/allisonhorst/palmerpenguins/master/man/figures/lter_penguins.png\" width=500 />\n",
    "\n",
    "*Artwork by @allison_horst*\n",
    "\n",
    "Data were collected and made available by [Dr. Kristen Gorman](https://www.uaf.edu/cfos/people/faculty/detail/kristen-gorman.php)\n",
    "and the [Palmer Station, Antarctica LTER](https://pal.lternet.edu/), a member of\n",
    "the [Long Term Ecological Research Network](https://lternet.edu/).\n",
    "\n",
    "Data are available by  [CC-0](https://creativecommons.org/share-your-work/public-domain/cc0/)\n",
    "license in accordance with the [Palmer Station LTER Data Policy](http://pal.lternet.edu/data/policies)\n",
    "and the [LTER Data Access Policy for Type I data](https://lternet.edu/data-access-policy/).\n",
    "\n",
    "Here we will use a subset of it, prepared for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4cd2af5-7787-47c3-a277-e913307e19c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7cfe32f-1061-400f-be92-b3cfbb61d6b8",
   "metadata": {},
   "source": [
    "## Loading and visualizing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaab3af-bba1-405f-bcef-5adcb80fd7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from penguins import load_penguins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b76881b-6624-4227-bdae-fe0ee2304c88",
   "metadata": {},
   "source": [
    "First, using the `load_penguins` function, load the data set and explore it.\n",
    "\n",
    "As you do it, answer the following questions:\n",
    "\n",
    "- how many features does it contain?\n",
    "- how many samples?\n",
    "- what is the target variable and how is it encoded?\n",
    "\n",
    "*Note: more information about the culmen measures are available [here](https://allisonhorst.github.io/palmerpenguins/#bill-dimensions).*\n",
    "\n",
    "**Hint: this section is very similar to the [Iris data set exploration in section 02.1](02.1-Machine-Learning-Intro.ipynb#Loading-the-Iris-Data-with-Scikit-Learn).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25500ca-87ed-4acb-abec-71c9e7ccd500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267fe7c4-003f-44eb-a98d-77da9402c539",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the size of the feature matrix \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0f1b8a-3d43-4b81-a241-0f7eb2dae18a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the name of the features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febefc8b-b961-4457-9280-3a12cb587c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the target variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce809a5-688c-4755-bd3c-b0c2bb8e03ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# and its possible values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e22af8-1ae0-4961-9201-89d8e9b2e0ac",
   "metadata": {},
   "source": [
    "Next, let's have a look at the data and see how the different species are\n",
    "distributed. Create a plot showing two of the dimensions of the dataset.\n",
    "\n",
    "*Bonus: you can create a function and use it in a loop to show all pairs of dimensions.*\n",
    "\n",
    "**Hint: this section is very similar to the [Iris data set exploration in section 02.1](02.1-Machine-Learning-Intro.ipynb#Loading-the-Iris-Data-with-Scikit-Learn).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc305da-6c68-45cf-812f-38a2f1cc134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create scatter plot to display two of the dimensions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5055e754-aeed-4526-92e7-4b30eba35650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bonus: plot all pairs of features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0e8ea9-1f87-4063-bc91-9d95ed5f5c35",
   "metadata": {},
   "source": [
    "### Question\n",
    "\n",
    "Given the nature of the dataset and the target data, what type of machine learning\n",
    "task are we trying to achieve (2 keywords)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93513c0c-55bf-417d-bedd-dadd28c32749",
   "metadata": {},
   "source": [
    "## Fit a model\n",
    "\n",
    "Now that we have loaded and explored the dataset, we can start fitting a model and measure its performance.\n",
    "\n",
    "You can start with a `LogisticRegression` model, as follows:\n",
    "\n",
    "1. split the data into a training and test datasets,\n",
    "2. import the `LogisticRegression` class and create the model,\n",
    "3. fit the model to the training dataset,\n",
    "4. generate predictions on the test dataset,\n",
    "5. compute the accuracy score of the model.\n",
    "\n",
    "Do not hesitate to try other models, for example a decision tree, a random forest or a K-nearest neighbors model.\n",
    "\n",
    "*Bonus: plot the corresponding confusion matrix.*\n",
    "\n",
    "**Hint: this section is very similar to the [classification on digits example in section 02.2](02.2-Basic-Principles.ipynb#Classification-on-Digits).**\n",
    "\n",
    "**Hint: the random forest model has been used a similar way in the [Random Forest for Classifying Digits in section 03.2](03.2-Regression-Forests.ipynb#Example:-Random-Forest-for-Classifying-Digits).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2950b1c0-40f5-4ec9-8ace-801a51f3dbd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the dataset in train / test folds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f924418e-0d78-4cc3-9c95-ca4780d00887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the LogisticRegression class, create a model and fit it to training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70718130-0a33-472f-8ff8-98c8ab0747b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict labels on the test data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a513cd1-a9df-4fe5-92a5-9e7f662a5f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the accuracy score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5459e71-1859-4500-84b7-0220d28f4b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bonus: display the confusion matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e0045a8-2c34-4bd9-92c4-885a9bd468c3",
   "metadata": {},
   "source": [
    "To improve the quantification of the model performance, use the `cross_val_score`\n",
    "function to compute 5 folds cross-validation estimation of the model accuracy.\n",
    "\n",
    "**Hint: this section is very similar to the [K-fold Cross-Validation in section 05](05-Validation.ipynb#K-fold-Cross-Validation).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e721c2-a96a-4d26-8307-abc3289a44aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the cross-validated accuracy score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3fee761-ea0b-432a-89f7-f02b556f5e6f",
   "metadata": {},
   "source": [
    "### Bonus questions\n",
    "\n",
    "- Use the `make_pipeline` function in combination with the `StandardScaler`\n",
    "  preprocessor to fit a logistic regression model with input normalization.\n",
    "- Use the `cross_val_predict` function to generate the confusion matrix for each\n",
    "  input data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca63e89-5bdc-4c75-beb0-2aaa90cc1c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a composite model using StandardScaler and LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16829de-a4dc-44ae-83e2-6eb0f501b30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a confusion matrix for cross-validated predictions\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
